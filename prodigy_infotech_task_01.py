# -*- coding: utf-8 -*-
"""Prodigy InfoTech_Task-01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12A3pbfDxiDt1T8OJBnta4vaYXuHT9euO

# Import important libraries
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

"""#Load the training data"""

trainData = pd.read_csv('/content/train.csv')

trainData.head()

"""#Preprocessing data

#Separate features and target value
"""

x = trainData.drop(columns=['GrLivArea', 'BedroomAbvGr', 'FullBath', 'HalfBath'])
y = trainData['SalePrice']

"""#Identify numerical and categories columns"""

num_features = X.select_dtypes(include=[np.number]).columns.tolist()
cat_features = X.select_dtypes(include=['object']).columns.tolist()

"""#Define preprocessing pipelines"""

num_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

cat_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

"""# Combine preprocessing pipelines"""

preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_pipeline, num_features),
        ('cat', cat_pipeline, cat_features)
    ])

"""# Apply the preprocessing steps to the dataset"""

X_preprocessed = preprocessor.fit_transform(X)

"""# Split the preprocessed data into training and validation sets"""

X_train, X_val, y_train, y_val = train_test_split(X_preprocessed, y, test_size = 0.2, random_state = 42)

"""# Welcome AI"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

model = LinearRegression()

model.fit(X_train, y_train)

y_pred_train = model.predict(X_train)
y_pred_val = model.predict(X_val)

"""# Evaluate the model"""

mse_train = mean_squared_error(y_train, y_pred_train)
mse_val = mean_squared_error(y_val, y_pred_val)

r2 = r2_score(y_val, y_pred_val)
print(r2)

"""#Test the AI model

#Load the input data from the file
"""

testData = pd.read_csv('/content/test.csv')

testData.head()

z = testData.drop(columns=['GrLivArea', 'BedroomAbvGr', 'FullBath', 'HalfBath'])

num_features = z.select_dtypes(include=[np.number]).columns.tolist()
cat_features = z.select_dtypes(include=['object']).columns.tolist()

num_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

cat_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_pipeline, num_features),
        ('cat', cat_pipeline, cat_features)
    ])

z_preprocessed = preprocessor.fit_transform(z)

"""#Make predictions using the trained model"""

for col in cat_features:
    train_unique = set(trainData[col].unique())
    test_unique = set(testData[col].unique())

    diff_train = train_unique - test_unique
    diff_test = test_unique - train_unique

preprocessor.fit(trainData)

z_preprocessed = preprocessor.transform(z)
train_data_preprocessed = preprocessor.transform(trainData)

model.fit(train_data_preprocessed, trainData['SalePrice'])

testData['SalePrice'] = model.predict(z_preprocessed)

"""#Save the predictions into a new file"""

testData.to_excel('/content/output_file.xlsx', index = False)